<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="UTF-8">
    <title>Tony | Shu </title>
    <link rel="icon" type="image/svg+xml" href="assets/img/urku-ico.svg">
    <link rel="stylesheet" href="assets/css/aurora-pack.min.css">
    <link rel="stylesheet" href="assets/css/aurora-theme-base.min.css">
    <link rel="stylesheet" href="assets/css/urku.css">
    <link rel="stylesheet" href="assets/css/modal.css">
    <link rel="icon" href="assets/img/favicon.ico">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>
  </head>
  <body class="top-fixed">
  	<div id="player"></div>

    <script>
      // 2. This code loads the IFrame Player API code asynchronously.
      var tag = document.createElement('script');

      tag.src = "https://www.youtube.com/iframe_api";
      var firstScriptTag = document.getElementsByTagName('script')[0];
      firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);
    </script>

    <header class="ae-container-fluid ae-container-fluid--full rk-header" id="topBar">
      <input type="checkbox" id="mobile-menu" class="rk-mobile-menu">
      <label for="mobile-menu">
        <svg>
          <use xlink:href="assets/img/symbols.svg#bar"></use>
        </svg>
        <svg>
          <use xlink:href="assets/img/symbols.svg#bar"></use>
        </svg>
        <svg>
          <use xlink:href="assets/img/symbols.svg#bar"></use>
        </svg>
      </label>
      <div class="ae-container-fluid rk-topbar">
        <h1 class="rk-logo"><a href="index">Tony|Shu</a></h1>
        <nav class="rk-navigation">
          <ul class="rk-menu">
            <li class="active rk-menu__item"><a href="index" class="rk-menu__link">Makes</a>
            </li>
            <li class="rk-menu__item"><a href="muses" class="rk-menu__link">Muses</a>
            </li>
            <li class="rk-menu__item"><a href="about" class="rk-menu__link">Me</a>
            </li>
          </ul>
        </nav>
      </div>
    </header>
    <section class="ae-container-fluid rk-main">
      <div class="ae-container-fluid ae-container-fluid--inner item-inside__meta">
      <h4 style="z-index:-1"> beauty from inter|faces </h4>
      <p>selected project summaries</p>
        <div class="ae-masonry ae-masonry-md-3">
          <button class="rk-item ae-masonry__item button" id="findEDButton"><img src="assets/img/findedHome.jpg" alt="">
                <div class="item-meta">
                  <h3>findED.io</h3>
                  <p>discover your best ER</p>
                  <p>data|health</p>
                </div></button>
            <div id="findEDModal" class="modal">
              <div class="modal-content">
                <img src="assets/img/findedResults.jpg">
		              <p style="text-align:left; margin: 20px">After observing how little access people have to medical treatment statistics, my colleagues and I decided to address the issue directly in a completely independent project. <a href="http://www.finded.io" style="text-decoration:underline" target="_blank">findED.io</a> is a webapp which combines hospital statistics from the Centers for Medicaid and Medicare Services Hospital
                Quality Initiative with data from Google Maps API to rank nearby hospitals by both total time until treatment and overall quality. Our site served over 50,000 unique visitors within 48 hours of launch.</p>
                  <p style="text-align:left; margin: 20px">For this project, my primary contributions were to the front end user experience. One of the biggest challenges with scientific data is its density. Understanding results usually requires significant domain knowledge beforehand, or else a significant amount of time invested into gaining the prerequisite vocabulary. After mining the hospital statistics report for data, my goal was to present a reactive and friendly interface to immediately convey to users wait times and a sense of hospital quality. The site relies on universal visual cues and symbolic representation to get this information across in an average of 1.5 minutes, important during emergencies when every second counts. However, for the user who wants more detail, clicking on the hospital panels reveals raw data in a graphical format. This decision was critical to fostering trust in the service through transparency and availability of information.
                  </p>
                  <p style="text-align:left; margin: 20px">The data we collected from user analytics after launch was massive. I interpreted these analytics for our technical paper which we decided to publish after development. I personally presented our paper at the Institute of Industrial Engineers Southeast Region Conference where it won the best technical paper award. Afterwards, the entire team was flown to Anaheim, CA to present at the international conference.
                  </p>
	                <p style="text-decoration:underline"><a href="assets/pdf/finded.pdf" target="_blank"> FindED.io - A Patient Decision Tool for Determining the
					Optimal Emergency Room for Non-Ambulance Emergencies</a></p>
	                <p style="text-decoration:underline"><a href="http://www.coe.gatech.edu/news/student-team-creates-tool-find-shortest-wait-time-hospital-emergency-rooms" target="_blank"> Winner of the 2016 IISE Southeast Region Technical Paper Competition</a></p>            
              </div>
            </div>


          <button class="rk-item ae-masonry__item button" id="recapButton"><img src="assets/img/recap.jpg" alt="">
                <div class="item-meta">
                  <h3>Project ReCap</h3>
                  <p>zirconia recyling initiative</p>
                  <p>materials|nature</p>
                </div></button>
            <div id="recapModal" class="modal">
                <div class="modal-content">
                  <img src="assets/img/recapTeeth.jpg">

				<div class="rk-blog__items">
		            <p style="text-align:left; margin: 20px">Over one million pounds of high-purity zirconia are thrown away annually as a result of the dental crown milling process, producing needless waste. In the subtractive milling process, 93% of each $200 zirconia blank gets consolidated as dust and chips into the dental lab waste stream. The accumulated debris is often combined with gypsum, wax, and metallic shavings from the lab's other processing streams. Though zirconia is desirable for use in ball milling media, precision valves, and high-wear components, impurities can not be tolerated. With sponsorship from 3M, My senior design team formulated a viable recycling stream for this material with minimal overhead cost for all industry parties involved.</p>

                <p style="text-align:left; margin: 20px">Our solution was to isolate and characterize this zirconia waste in order to ship it off to raw materials processing companies for recycling. To demonstrate the viability of our method, we first filtered out powdered material from the waste stream using a cyclone separator. Our team then performed multiple characterization tests to create a datasheet for potential companies who might be interested in recycling the material. I personally developed a method of estimating the composition of the collected powder based on known densities of the input material and particle size while considering the effects of sphere packing. I also established a trial recycling program with Saint-Gobain, formulating a viable shipping strategy to get powder from dental labs to processing plants without undue cost. 
                </p>
	                  <p style="text-decoration:underline"><a href="assets/pdf/recapFinal.pdf" target="_blank">Project ReCap: Recycling of Dental Crown Byproducts
						</a></p>
	                  <p style="text-decoration:underline"><a href="http://coe.gatech.edu/news/capstone-design-spring-2016-winners" target="_blank"> 1st place Materials Science project at the 2016 Georgia Tech Capstone Expo</a></p>
		        </div>                       
                </div>
            </div>

          <button class="rk-item ae-masonry__item button" id="banditButton"><img src="assets/img/bandit.jpeg" alt="">
                <div class="item-meta">
                  <h3>Bandit</h3>
                  <p>modular wearable sensor package</p>
                  <p>reality|binary</p>
                </div></button>
            <div id="banditModal" class="modal">
              <div class="modal-content">
                <img src="assets/img/bandit.jpg">
                <div class="rk-blog__items">
		              <p style="text-align:left; margin: 20px"> Bandit is a wearable with all the functionality of existing fitness trackers and then some. It houses six completely modular sensor bays large enough for anything from geiger counters to run-of-the-mill accelerometers. With a variety of mounting options à la GoPro, Bandit is the complete sensor package for anyone: surfers, rally drivers, triathletes, moms, nuclear physicists, etc. The goal of this materials science design project was to work as a team to consider all of the steps required for getting a product to market. </p>

                  <p style="text-align:left; margin: 20px">As team lead, my role consisted of configuring the electronics and making a working three sensor prototype capable of sensor hot-swapping. I developed a minimum viable product using an Arduino with various off-the-shelf sensors. Hot-swapping was implemented through embedded sensor APIs, and Processing was used as a data visualizer. We explored a wide range of wearable technologies including room temperature thermoelectric generators, hypoallergenic elastomers, and advanced waterproofing techniques.
	                </p>
	                <p><a href="assets/pdf/banditFinal.pdf" target="_blank" style="text-decoration:underline">Bandit - A Modular Sensor Package for Triathletes</a></p><p>
	                <a href="https://github.com/tshu/partModels/blob/master/11.30.SLDPRT" target="_blank" style="text-decoration:underline">Part Model</a></p>
		        </div> 
              </div>
            </div>           
          <button class="rk-item ae-masonry__item button" id="amproButton"><img src="assets/img/ampro3.jpg" alt="">
                <div class="item-meta">
                  <h3>AMPRO3</h3>
                  <p>powered transfemoral prosthesis</p>
                  <p>man|machine</p>
                </div></button>
            <div id="amproModal" class="modal">
              <div class="modal-content">
                <iframe width="90%" height="394" src="https://www.youtube.com/embed/Aq8_H_nSAxI?rel=0&enablejsapi=1" frameborder="0" allowfullscreen id="amproVideo"></iframe>
                <div class="rk-blog__items">
		              <p style="text-align:left; margin: 20px"> Prosthesis technology is quickly catching up to meet the demands of everyday life. As part of the <a href="http://www.bipedalrobotics.com" style="text-decoration:underline" target="_blank">AMBER Lab</a>, I am the project manager of AMPRO3, a transfemoral prosthesis featuring actuated knee and ankle joints. Utilizing a hybrid zero dynamics framework to drive the system toward human-inspired reference trajectories, AMPRO3 will serve as a platform for future cost of transportation and walking gait studies. My team of graduate students is currently developing several novel feedback controllers for the accurate tracking of reference trajectories.</p>

                  <p style="text-align:left; margin: 20px">AMPRO3 is something I have been working on for over a year, and the potential of prosthesis research continues to inspire me every day. In addition to making use of the device's series elastic actuators, relative encoders, motor drivers, inertial measurement units, and custom circuitry, I have written a custom API for the six-axis load cell located at the ankle which allows for the measurement of ground reaction forces. I have also experimentally implemented and tuned several theoretical passivity-based, adaptive, and sliding mode controllers in ROS using its on-board BeagleBone Black microcontroller. Our work on this generation of AMPRO has produced a manuscript which will appear in the 2017 American Controls Conference proceedings and another journal manuscript which will be submitted in January 2016.
	                </p>
	                <p><a href="assets/pdf/amproControl1.pdf" style="text-decoration:underline" target="_blank">Manuscript submission to the 2017 American Controls Conference</a></p>
	                <p><a href="https://github.com/tshu/optoforce6axis" target="_blank" style="text-decoration:underline"> Source</a> for my custom API used to integrate an OptoForce six-axis load cell with the ankle joint for the measurement of ground reactions.</p>
		        </div> 
              </div>
            </div> 

          <button class="rk-item ae-masonry__item button" id="dmlsButton" style="margin-top: 1px"><img src="assets/img/dmls.jpg" alt="">
                <div class="item-meta">
                  <h3>This thing</h3>
                  <p>direct metal laser sintering</p>
                  <p>energy|art</p>
                </div></button>
            <div id="dmlsModal" class="modal">
              <div class="modal-content">
                <img src="assets/img/print1.jpg">
                <img src="assets/img/dice.jpg">
		            <div class="blog-info">
		              <p style="text-align:left; margin: 20px"> Examining the microstructure of printed components can yield fundamental relationships between printing pattern algorithms, laser energy density, and structural integrity. In the summer of 2014, I started research at SpaceX where I designed new algorithms to balance energy density gradients for sintering lasers deviating from true focus. I gained hands-on expertise in direct metal laser sintering of Inconel 718 and Ti6Al4V superalloy powders. After several weeks of troubleshooting, I discovered key relationships between processing parameters and component integrity which would make traditionally impossible printing overhang angles feasible. With these new techniques, even completely spherical shells can be sintered without any interior support. 
                	</p>
                  <p style="text-align:left; margin: 20px"> I also developed a metal powder characterization lab setup to verify the composition of supplier powders. Tests include particle diffraction analysis for size distribution, inductively coupled plasma spectroscopy for composition, and powder flow analysis. Instead of outsourcing these tests, SpaceX saves $150,000 in operating costs every year.
                  </p>

			           </div>
              </div>
            </div> 

          <button class="rk-item ae-masonry__item button" id="ravenButton"><img src="assets/img/raven.PNG" alt="">
                <div class="item-meta">
                  <h3>Raven's Progressive Matrices</h3>
                  <p>pattern recognition</p>
                  <p>vision|intelligence</p>
                </div>
          </button>
            <div id="ravenModal" class="modal">
              <div class="modal-content">
                <img src="assets/img/ravenb.PNG">
                <div class="rk-blog__items">
                  <p style="text-align:left; margin: 20px"> While machine learning techniques have their place, many patterns cannot be reduced to a feasible feature space. As a project for Dr. Ashok Goel's course on Knowledge-Based AI (of <a href="http://www.businessinsider.com/watson-ai-became-a-teaching-assistant-2016-5" target="_blank" style="text-decoration:underline"> Jill Watson</a> fame), I have created an intelligent agent which uses reasoning to solve Raven's problems. These visual puzzles require the test taker to extract implicit patterns from a series of figures, applying them to select the correct answer from a bank. While the problems are intuitive for humans, a state-of-the-art agent is only correct around 70% of the time.
                  </p>
                  <p style="text-align:left; margin: 20px"> On an implementation level using the Pillow library, my agent performs pixel level statistical analysis and gross transformations on the given figures. Tiers of reasoning progress from simple screens of bitmap identity to figure rotations to pixel density matching. Whatever relationships are found are then appropriately implemented either horizontally, vertically, or diagonally. The agent follows up with a generate-and-test approach at the end of each tier to produce a best guess for that tier. Finally, a unified accuracy metric for guess comparison allows the agent to select the best answer choice. Using this strategy, the agent achieves 55% accuracy without relying on any semantic knowledge or object detection.
                  </p>
                </div> 
              </div>
            </div>

          <button class="rk-item ae-masonry__item button" id="crystalButton" style="margin-top: 2px"><img src="assets/img/crystal1.jpg" alt="">
                <div class="item-meta">
                  <h3>Cellulose Composites</h3>
                  <p>environmental degradation</p>
                  <p>materials|nature</p>
                </div>
          </button>
            <div id="crystalModal" class="modal">
              <div class="modal-content">
                <img src="assets/img/crystal2.png">
                <img src="assets/img/graph.jpg">
                <div class="rk-blog__items">
                  <p style="text-align:left; margin: 20px"> Cellulose is a naturally occurring polymer which can be found as a structural component in the cell walls of plants and algae. Its widespread biological utilization causes it to be the most abundant polymer resource in the world, and just as abundant are its many applications. A relatively new field of study concerns the application and role of cellulose used in nanocomposites. Polyhydroxybutyrate (PHB) is a semicrystalline biopolymer with a slow crystallization rate, which makes it an ideal matrix for crystallization behavior observations. The addition of cellulose nanocrystals (CNC) serves to inoculate an otherwise very pure (PHB has fewer than 200 ppm impurities) phase, isolating the effects of nanoparticle loading on the material.
                  </p>
                  <p style="text-align:left; margin: 20px"> With sponsorship from TenCate Protective Fabrics, I worked under the direct supervision of Dr. Stephanie Lin to characterize the biodegradation behavior of CNC/PHB composites. I started by preparing both solvent cast and compression molded samples of various CNC loading. These samples' crystallization kinetics were observed under hot stage microscopy where I discovered that compression molded samples crystallized much faster with a higher rate of nucleation compared to solvent cast samples at the same load. Fourier Transform infrared spectroscopy techniques were used to monitor the bond structure of these samples as they aged over a period of three months in both air and soil. I found that there were fewer extreme peaks in the 3800-2800 cm-1 region of aged samples vs. new samples, and aged samples contained a greater range of bond stretch types which correspond to a change in chemical composition and structure. Between samples, these changes were much more prevalent in those aged in soil.
                  </p>
                  <p style="text-align:left; margin: 20px"> The findings suggest that the physical properties CNC composites are highly tuneable based on both manufacturing methods and CNC loading. Specifically, a wide range of CNC/PHB composites are possible which should perform well in dry environments while degrading in the presence of moisture and bacteria.</p>
                </div> 
              </div>
            </div>       

          <button class="rk-item ae-masonry__item button" id="cameraButton" style="margin-top: 4px" title="Courtesy Greg Borenstein under Creative Commons 2.0"> <img src="assets/img/haarFace.jpg" alt="">
                <div class="item-meta">
                  <h3>Scout</h3>
                  <p>haar cascades</p>
                  <p>vision|art</p>
                </div>
          </button>
            <div id="cameraModal" class="modal">
              <div class="modal-content">
                <img src="assets/img/gnomes.jpg">
                <div class="rk-blog__items">
                  <p style="text-align:left; margin: 20px"> As a photographer, there are moments when I am nowhere near the camera, meaning I have to run back several yards just to pan it an inch. To address this issue I am developing Scout, a modular stepper motor/Raspberry Pi system to facilitate remote tracking. With any camera mounted to the stepper motor, the Raspberry Pi will be able to use a separate on-board camera to center the mounted camera toward signs held up by the photographer. Additionally, bluetooth communication with the Pi will allow manual tracking with a corresponding mobile app.
                  </p>
                  <p style="text-align:left; margin: 20px"> Automatic tracking should be possible by training a Haar cascade filter, which is a technique based on weak classifiers and AdaBoost for object discrimination. For each layer in the cascade, the filter searches for the existence of several features in the image which correspond to a specific object. Any portion of the image which meets the requirements for a single layer moves on to the next, discarding more of the image at each step. Eventually, the algorithm returns a selection of pixels which it believes to be the object it's looking for.
                  </p>
                  <p style="text-align:left; margin: 20px"> While cascade filters are extremely powerful, they are also very sensitive to noise. Detecting 10 out of 10 faces does not mean being able to tell them apart. I learned this the hard way after using OpenCV to train a cascade filter on hand symbols, which were interpreted as the same bowl of oatmeal for all I know. With the hardware assembled, my next step is to investigate using printed 2D symbols which can be selectively displayed. Combined with the commercially available mobile app for accessing camera functions, I expect Scout to excel at panoramas and group shots once it's complete.
                  </p>
                </div> 
              </div>
            </div>   

        </div>
      </div>
    </section>
      
    <footer class="ae-container-fluid rk-footer ">
      <div class="ae-grid ae-grid--collapse">
        <div class="ae-grid__item item-lg-4 au-xs-ta-center au-lg-ta-left">
          <p class="rk-footer__text rk-footer__copy "> <span class="ae-u-bold">© </span><span class="ae-u-bolder">2016 Tony Shu </span>All Rights Reserved.</p>
          <p class="rk-footer__text rk-footer__by">Theme by <a href="http://pixeden.com" class="ae-u-bolder">Pixeden.</a></p>
        </div>
        <div class="ae-grid__item item-lg-4 au-xs-ta-center">
          <a href="https://www.linkedin.com/in/tonyshu" class="rk-social-btn" target="_blank" style="-webkit-filter:grayscale(100%)">
          <img src="assets/img/linkedin.gif"></a>

          <a href="https://github.com/tshu" class="rk-social-btn" target="_blank">
          <img src="assets/img/github.png"></a>
        </div>
        <div class="ae-grid__item item-lg-4 au-xs-ta-center au-lg-ta-right">
          <p class="rk-footer__text rk-footer__contact "> <span class="ae-u-bold">Email: </span><span class="ae-u-bolder"> <a href="mailto:toekneeshu@gmail.com?subject=Hi Tony!" class="rk-dark-color "> toekneeshu@gmail.com </a></span></p>
          <p class="rk-footer__text rk-footer__by" style="color:#E95420"><a href="assets/pdf/resumeShu.pdf" class="ae-u-bolder" target="_blank">Résumé</a></p>
        </div>
      </div>
    </footer>
    
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-88679369-1', 'auto');
    ga('send', 'pageview');

    </script>
    <script src="assets/js/svg4everybody.min.js"></script>
    <script>svg4everybody();</script>
    <script src="assets/js/modal.js"></script>
    <script>
    	var player;
    	function onYouTubePlayerAPIReady() {player = new YT.Player('amproVideo');}

    	$('#amproModal').click(function(){
        	player.stopVideo();
		});	
    </script>

  </body>
</html>